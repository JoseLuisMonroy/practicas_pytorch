{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diseño de experimento\n",
    "## Una variable a la vez\n",
    "\n",
    "El enfoque de diseño de experimentos de una variable a la vez (One Variable At a Time, OVAT) es una metodología simple en la que se varía un solo factor o variable experimental mientras se mantienen constantes todos los demás factores. Este enfoque permite observar cómo cambios en esa única variable afectan el resultado del experimento. \n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/irvingvasquez/practicas_pytorch/blob/master/soluciones/06_doe_una_variable.ipynb)\n",
    "\n",
    "Si ejecutas en COLAB debes copiar los archivos extra de este repositorio.\n",
    "\n",
    "@juan1rving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos paquetes necesarios\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#helper was developed by Udacity under MIT license\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Definición de variables y rango de valores:\n",
    "\n",
    "Identificar los factores o variables experimentales clave que se desean estudiar. En el contexto de redes neuronales, estas variables pueden incluir la tasa de aprendizaje, el número de capas, el número de neuronas por capa, el tamaño del lote, entre otros.\n",
    "\n",
    "Variables que tomaremos en cuenta:\n",
    "\n",
    "- Tasa de aprendizaje (eta)\n",
    "- Número de épocas (n_epocas)\n",
    "- Tamaño de lote (batch_size)\n",
    "\n",
    "Una vez definidas las variables independientes definimos un rango de valores posibles para cada variable.\n",
    "\n",
    "> TODO: Define un rango de valores posibles para cada variable. Incluye el valor mínimo y el valor máximo. Se sugiere utilizar una lista de valores obtenida con una separación uniforme. Probar almenos 5 valores por variable.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Define rangos para los hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Configuración inicial:\n",
    "\n",
    "Establecer una configuración inicial para la red neuronal con valores predeterminados para todos los hiperparámetros. \n",
    "\n",
    "> TODO: Define la configuración inicial. Se sugiere usar un diccionario para contener dicha configuración.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "configuracion = {'eta': 0, 'epochs': 0, 'batch_size': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Variación de una variable a la vez:\n",
    "\n",
    "- Seleccionar la primera variable a estudiar (por ejemplo, la tasa de aprendizaje).\n",
    "- Realizar una serie de experimentos donde se varía únicamente la tasa de aprendizaje, mientras se mantienen constantes todos los demás hiperparámetros.\n",
    "- Registrar el rendimiento del modelo para cada valor de la tasa de aprendizaje.\n",
    "\n",
    "> TODO: Modifica el código para que pueda aceptar la configuración deseada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una transformación de los datos\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5), (0.5))])\n",
    "# Descargamos el conjunto de entrenamiento y cargamos mediante un dataLoader\n",
    "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Descargamos el conjunto de validación\n",
    "validationset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "validationloader = torch.utils.data.DataLoader(validationset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedNeuronal(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, drop_p = 0.5):\n",
    "        '''\n",
    "        Construye una red de tamaño arbitrario.\n",
    "        \n",
    "        Parámetros:\n",
    "        input_size: cantidad de elementos en la entrada\n",
    "        output_size: cantidada de elementos en la salida \n",
    "        hidden_layers: cantidad de elementos por cada capa oculta\n",
    "        drop_p: probabilidad de \"tirar\" (drop) una neurona [0,1] \n",
    "        '''\n",
    "        # llamamos al constructor de la superclase\n",
    "        super().__init__()\n",
    "        \n",
    "        # Agregamos la primera capa\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        \n",
    "        # agregamos cada una de las capas, zip empareja el número de entradas con las salidas\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        \n",
    "        # agregamos la capa de salida final de la red\n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        \n",
    "        # Incluimos drop-out en la red\n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Pase hacia adelante en la red, el regreso son las probabilidades en el dominio log '''\n",
    "        \n",
    "        # Hacemos un pase frontal en cada una de las capas ocultas, \n",
    "        # La funció de activación es un RELU combinado con dropout\n",
    "        for linear in self.hidden_layers:\n",
    "            x = F.relu(linear(x))\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network, define the criterion and optimizer\n",
    "model = RedNeuronal(784, 10, [516, 256], drop_p=0.5)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementamos una función de evaluación\n",
    "def validation(model, validationloader, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    for images, labels in validationloader:\n",
    "\n",
    "        images.resize_(images.shape[0], 784)\n",
    "\n",
    "        output = model.forward(images)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "\n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hiperparámetro\n",
    "epochs = 2\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 40\n",
    "for e in range(epochs):\n",
    "    # Cambiamos a modo entrenamiento\n",
    "    model.train()\n",
    "    for images, labels in trainloader:\n",
    "        steps += 1\n",
    "        \n",
    "        # Aplanar imágenes a un vector de 784 elementos\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        # Backprogamation\n",
    "        loss.backward()\n",
    "        # Optimización\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            # Cambiamos a modo de evaluación\n",
    "            model.eval()\n",
    "            \n",
    "            # Apagamos los gradientes, reduce memoria y cálculos\n",
    "            with torch.no_grad():\n",
    "                test_loss, accuracy = validation(model, validationloader, criterion)\n",
    "                \n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Pérdida de entrenamiento: {:.3f}.. \".format(running_loss/print_every),\n",
    "                  \"Pérdida de validación: {:.3f}.. \".format(test_loss/len(validationloader)),\n",
    "                  \"Exactitud de validación: {:.3f}\".format(accuracy/len(validationloader)))\n",
    "            \n",
    "            running_loss = 0\n",
    "            \n",
    "            # Make sure training is back on\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Selección del mejor valor:\n",
    "\n",
    "Analizar los resultados y seleccionar el valor de la tasa de aprendizaje que produce el mejor rendimiento del modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Repetición para otras variables:\n",
    "\n",
    "Proceder con la siguiente variable (por ejemplo, el número de capas) y repetir el proceso: variar solo esta variable mientras se mantienen constantes todos los demás hiperparámetros, utilizando el mejor valor encontrado para la tasa de aprendizaje. Continuar este proceso para cada variable en la lista.\n",
    "\n",
    "> TODO: Escribe una tabla con el resultado de cada experimento. Las columnas deben ser: ID, Configuración, Exactitud obtenida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "¿Cual fue el mejor valor encontrado?\n",
    "¿Cuantas ejecuciones se realizaron?\n",
    "¿Que tiempo tomó realizar todos los experimentos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_1_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
